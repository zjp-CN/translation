---

## layout: post
title: 'Dyn async traits, part 8: the soul of Rust'
date: 2022-09-18 13:49 -0400

## ç‰ˆé¢ï¼šå¸–å­æ ‡é¢˜ï¼šã€ŠDyn Async Charactersï¼ŒPart 8ï¼šTheçµé­‚of Rustã€‹æ—¥æœŸï¼š2022-09-18 13ï¼š49-0400

In the last few months, Tyler Mandry and I have been circulating a [â€œUserâ€™s Guide from the Futureâ€](https://hackmd.io/@nikomatsakis/SJ2-az7sc) that describes our current proposed design for async functions in traits. In this blog post, I want to deep dive on one aspect of that proposal: how to handle dynamic dispatch. My goal here is to explore the space a bit and also to address one particularly tricky topic: how explicit do we have to be about the possibility of allocation? This is a tricky topic, and one that gets at that core question: what is the soul of Rust?

åœ¨è¿‡å»çš„å‡ ä¸ªæœˆé‡Œï¼Œæ³°å‹’Â·æ›¼å¾·é‡Œå’Œæˆ‘ä¸€ç›´åœ¨åˆ†å‘ä¸€ä»½ã€Šæ¥è‡ªæœªæ¥çš„ç”¨æˆ·æŒ‡å—ã€‹ï¼Œå…¶ä¸­æè¿°äº†æˆ‘ä»¬ç›®å‰ä¸ºç‰¹å¾ä¸­çš„å¼‚æ­¥åŠŸèƒ½æå‡ºçš„è®¾è®¡æ–¹æ¡ˆã€‚åœ¨è¿™ç¯‡åšå®¢æ–‡ç« ä¸­ï¼Œæˆ‘æƒ³æ·±å…¥æ¢è®¨è¯¥å»ºè®®çš„ä¸€ä¸ªæ–¹é¢ï¼šå¦‚ä½•å¤„ç†åŠ¨æ€è°ƒåº¦ã€‚æˆ‘åœ¨è¿™é‡Œçš„ç›®æ ‡æ˜¯æ¢ç´¢ä¸€ä¸‹è¿™ä¸ªç©ºé—´ï¼Œå¹¶è§£å†³ä¸€ä¸ªç‰¹åˆ«æ£˜æ‰‹çš„è¯é¢˜ï¼šæˆ‘ä»¬å¿…é¡»å¯¹åˆ†é…çš„å¯èƒ½æ€§æœ‰å¤šæ˜ç¡®ï¼Ÿè¿™æ˜¯ä¸€ä¸ªæ£˜æ‰‹çš„è¯é¢˜ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªåˆ‡ä¸­æ ¸å¿ƒé—®é¢˜çš„è¯é¢˜ï¼šé“é”ˆçš„çµé­‚æ˜¯ä»€ä¹ˆï¼Ÿ

### The running example trait

### æ­£åœ¨è¿è¡Œçš„ç¤ºä¾‹ç‰¹å¾

Throughout this blog post, I am going to focus exclusively on this example trait, `AsyncIterator`:

åœ¨è¿™ç¯‡åšå®¢æ–‡ç« ä¸­ï¼Œæˆ‘å°†ä¸“é—¨å…³æ³¨è¿™ä¸ªç¤ºä¾‹ç‰¹å¾ï¼Œ`AsyncIterator`ï¼š

```rust
trait AsyncIterator {
    type Item;
    async fn next(&mut self) -> Option<Self::Item>;
}
```

And weâ€™re particularly focused on the scenario where we are invoking `next` via dynamic dispatch:

æˆ‘ä»¬ç‰¹åˆ«å…³æ³¨é€šè¿‡åŠ¨æ€è°ƒåº¦è°ƒç”¨`next`çš„åœºæ™¯ï¼š

```rust
fn make_dyn<AI: AsyncIterator>(ai: AI) {
    use_dyn(&mut ai); // <â€” coercion from `&mut AI` to `&mut dyn AsyncIterator`
}

fn use_dyn(di: &mut dyn AsyncIterator) {
    di.next().await; // <â€” this call right here!
}
```

Even though Iâ€™m focusing the blog post on this particular snippet of code, everything Iâ€™m talking about is applicable to any trait with methods that return `impl Trait` (async functions themselves being a shorthand for a function that returns `impl Future`).

å°½ç®¡æˆ‘çš„åšå®¢æ–‡ç« å°†é‡ç‚¹æ”¾åœ¨è¿™æ®µç‰¹å®šçš„ä»£ç ä¸Šï¼Œä½†æˆ‘æ‰€è®¨è®ºçš„æ‰€æœ‰å†…å®¹éƒ½é€‚ç”¨äºå…·æœ‰è¿”å›`impl Trait`çš„æ–¹æ³•çš„ä»»ä½•ç‰¹å¾(å¼‚æ­¥å‡½æ•°æœ¬èº«æ˜¯è¿”å›`impl Future`çš„å‡½æ•°çš„ç®€å†™)ã€‚

The basic challenge that we have to face is this:

æˆ‘ä»¬å¿…é¡»é¢å¯¹çš„åŸºæœ¬æŒ‘æˆ˜æ˜¯ï¼š

* The caller function, `use_dyn`, doesnâ€™t know what impl is behind the `dyn`, so it needs to allocate a fixed amount of space that works for everybody. It also needs some kind of vtable so it knows what `poll` method to call.
* The callee, `AI::next`, needs to be able to package up the future for its `next` function in some way to fit the callerâ€™s expectations.

The [first blog post in this series](https://smallcultfollowing.com/babysteps/blog/2021/09/30/dyn-async-traits-part-1/)[^2020] explains the problem in more detail.

è°ƒç”¨æ–¹å‡½æ•°`use_dyn`ä¸çŸ¥é“`dyn`åé¢çš„implæ˜¯ä»€ä¹ˆï¼Œæ‰€ä»¥å®ƒéœ€è¦åˆ†é…ä¸€ä¸ªå›ºå®šå¤§å°çš„ç©ºé—´ï¼Œæ¯ä¸ªäººéƒ½å¯ä»¥ä½¿ç”¨ã€‚å®ƒè¿˜éœ€è¦æŸç§vtableï¼Œè¿™æ ·å®ƒæ‰çŸ¥é“è¦è°ƒç”¨ä»€ä¹ˆ`poll`æ–¹æ³•ã€‚è¢«è°ƒç”¨æ–¹`AIï¼šï¼šnext`éœ€è¦èƒ½å¤Ÿä»¥æŸç§æ–¹å¼ä¸ºå…¶`next`å‡½æ•°æ‰“åŒ…æœªæ¥ï¼Œä»¥æ»¡è¶³è°ƒç”¨æ–¹çš„æœŸæœ›ã€‚æœ¬ç³»åˆ—çš„ç¬¬ä¸€ç¯‡åšå®¢æ–‡ç« æ›´è¯¦ç»†åœ°è§£é‡Šäº†è¿™ä¸ªé—®é¢˜ã€‚

[^2020]: Written in Sep 2020, egads!

å†™äº2020å¹´9æœˆï¼Œå¤©å“ªï¼

### A brief tour through the options

### ç®€è¦ä»‹ç»è¿™äº›é€‰é¡¹

One of the challenges here is that there are many, many ways to make this work, and none of them is â€œobviously bestâ€. What follows is, I think, an exhaustive list of the various ways one might handle the situation. If anybody has an idea that doesnâ€™t fit into this list, Iâ€™d love to hear it.

è¿™é‡Œé¢ä¸´çš„æŒ‘æˆ˜ä¹‹ä¸€æ˜¯ï¼Œæœ‰å¾ˆå¤šå¾ˆå¤šæ–¹æ³•å¯ä»¥åšåˆ°è¿™ä¸€ç‚¹ï¼Œä½†æ²¡æœ‰ä¸€ç§æ–¹æ³•â€œæ˜¾ç„¶æ˜¯æœ€å¥½çš„â€ã€‚æˆ‘è®¤ä¸ºï¼Œä»¥ä¸‹æ˜¯ä¸€ä¸ªäººå¯èƒ½å¤„ç†è¿™ç§æƒ…å†µçš„å„ç§æ–¹æ³•çš„è¯¦å°½æ¸…å•ã€‚å¦‚æœæœ‰äººæœ‰ä¸ç¬¦åˆè¿™ä¸ªæ¸…å•çš„æƒ³æ³•ï¼Œæˆ‘å¾ˆä¹æ„å¬å¬ã€‚

**Box it.** The most obvious strategy is to have the callee box the future type, effectively returning a `Box<dyn Future>`, and have the caller invoke the `poll` method via virtual dispatch. This is what the [`async-trait`](https://crates.io/crates/async-trait) crate does (although it also boxes for static dispatch, which we donâ€™t have to do).

æŠŠå®ƒè£…ä¸Šç›’å­ã€‚æœ€æ˜æ˜¾çš„ç­–ç•¥æ˜¯è®©è¢«è°ƒç”¨æ–¹æ¡†ä¸ºFutureç±»å‹ï¼Œæœ‰æ•ˆåœ°è¿”å›ä¸€ä¸ª`Box<dyn Future>`ï¼Œå¹¶è®©è°ƒç”¨æ–¹é€šè¿‡è™šæ‹Ÿåˆ†æ´¾è°ƒç”¨`poll`æ–¹æ³•ã€‚è¿™å°±æ˜¯â€˜Async-Trait`æ¿æ¡ç®±â€™æ‰€åšçš„(å°½ç®¡å®ƒä¹Ÿå¯¹é™æ€åˆ†æ´¾è¿›è¡Œè£…ç®±ï¼Œè¿™æ˜¯æˆ‘ä»¬ä¸å¿…åšçš„)ã€‚

**Box it with some custom allocator.** You might want to box the future with a custom allocator.

ç”¨ä¸€äº›å®šåˆ¶çš„åˆ†é…å™¨æŠŠå®ƒè£…ç®±ã€‚æ‚¨å¯èƒ½å¸Œæœ›ä½¿ç”¨è‡ªå®šä¹‰åˆ†é…å™¨æ¥è£…ç®±æœªæ¥ã€‚

**Box it and cache box in the caller.** For most applications, boxing itself is not a performance problem, unless it occurs repeatedly in a tight loop. Mathias Einwag pointed out if you have some code that is repeatedly calling `next` on the same object, you could have that caller cache the box in between calls, and have the callee reuse it. This way you only have to actually allocate once.

å°†å…¶è£…ç®±å¹¶å°†å…¶ç¼“å­˜åœ¨è°ƒç”¨æ–¹ä¸­ã€‚å¯¹äºå¤§å¤šæ•°åº”ç”¨ç¨‹åºæ¥è¯´ï¼Œè£…ç®±æœ¬èº«å¹¶ä¸æ˜¯æ€§èƒ½é—®é¢˜ï¼Œé™¤éå®ƒåœ¨ä¸€ä¸ªç´§å¯†çš„å¾ªç¯ä¸­é‡å¤å‡ºç°ã€‚Mathias EinwagæŒ‡å‡ºï¼Œå¦‚æœä½ æœ‰ä¸€äº›ä»£ç åœ¨åŒä¸€ä¸ªå¯¹è±¡ä¸Šé‡å¤è°ƒç”¨`next`ï¼Œä½ å¯ä»¥è®©è°ƒç”¨è€…åœ¨è°ƒç”¨ä¹‹é—´ç¼“å­˜ç›’å­ï¼Œå¹¶è®©è¢«è°ƒç”¨è€…é‡å¤ä½¿ç”¨å®ƒã€‚è¿™æ ·ï¼Œæ‚¨åªéœ€å®é™…åˆ†é…ä¸€æ¬¡ã€‚

**Inline it into the iterator.** Another option is to store all the state needed by the function in the `AsyncIter` type itself. This is actually what the existing `Stream` trait does, if you think about it: instead of returning a future, it offers a `poll_next` method, so that the implementor of `Stream` effectively *is* the future, and the caller doesnâ€™t have to store any state. Tyler and I worked out a more general way to do inlining that doesnâ€™t require user intervention, where you basically wrap the `AsyncIterator` type in another type `W` that has a field big enough to store the `next` future. When you call `next`, this wrapper `W` stores the future into that field and then returns a pointer to the field, so that the caller only has to poll that pointer. **One problem with inlining things into the iterator is that it only works well for `&mut self` methods**, since in that case there can be at most one active future at a time. With `&self` methods, you could have any number of active futures.

å°†å…¶å†…è”åˆ°è¿­ä»£å™¨ä¸­ã€‚å¦ä¸€ç§é€‰æ‹©æ˜¯å°†å‡½æ•°éœ€è¦çš„æ‰€æœ‰çŠ¶æ€å­˜å‚¨åœ¨`AsyncIter`ç±»å‹æœ¬èº«ä¸­ã€‚è¿™å®é™…ä¸Šå°±æ˜¯ç°æœ‰çš„`Stream`ç‰¹å¾æ‰€åšçš„ï¼Œå¦‚æœä½ ä»”ç»†æƒ³æƒ³çš„è¯ï¼šå®ƒä¸æ˜¯è¿”å›æœªæ¥ï¼Œè€Œæ˜¯æä¾›äº†ä¸€ä¸ª`polnext`æ–¹æ³•ï¼Œæ‰€ä»¥`Stream`çš„å®ç°è€…å®é™…ä¸Šå°±æ˜¯æœªæ¥ï¼Œè°ƒç”¨è€…ä¸å¿…å­˜å‚¨ä»»ä½•çŠ¶æ€ã€‚æ³°å‹’å’Œæˆ‘è®¾è®¡äº†ä¸€ç§æ›´é€šç”¨çš„å†…è”æ–¹æ³•ï¼Œè¿™ç§æ–¹æ³•ä¸éœ€è¦ç”¨æˆ·å¹²é¢„ï¼ŒåŸºæœ¬ä¸Šæ˜¯å°†`AsyncIteratorâ€˜ç±»å‹åŒ…è£…åœ¨å¦ä¸€ç§ç±»å‹`Wâ€™ä¸­ï¼Œè¯¥ç±»å‹çš„å­—æ®µè¶³å¤Ÿå¤§æ¥å­˜å‚¨`Nextâ€˜çš„æœªæ¥ã€‚å½“æ‚¨è°ƒç”¨`next`æ—¶ï¼Œè¿™ä¸ªåŒ…è£…å™¨`W`å°†æœªæ¥å­˜å‚¨åˆ°è¯¥å­—æ®µä¸­ï¼Œç„¶åè¿”å›æŒ‡å‘è¯¥å­—æ®µçš„æŒ‡é’ˆï¼Œå› æ­¤è°ƒç”¨è€…åªéœ€è½®è¯¢è¯¥æŒ‡é’ˆã€‚å°†å¯¹è±¡å†…è”åˆ°è¿­ä»£å™¨çš„ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œå®ƒåªé€‚ç”¨äº`&mut selfâ€˜æ–¹æ³•ï¼Œå› ä¸ºåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä¸€æ¬¡æœ€å¤šåªèƒ½æœ‰ä¸€ä¸ªæ´»åŠ¨çš„æœªæ¥ã€‚ä½¿ç”¨`&selfâ€˜æ–¹æ³•ï¼Œæ‚¨å¯ä»¥æ‹¥æœ‰ä»»æ„æ•°é‡çš„æ´»è·ƒæœŸè´§ã€‚

**Box it and cache box in the callee.** Instead of inlining the entire future into the `AsyncIterator` type, you could inline just one pointer-word slot, so that you can cache and reuse the `Box` that `next` returns. The upside of this strategy is that the cached box moves with the iterator and can potentially be reused across callers. The downside is that once the caller has finished, the cached box lives on until the object itself is destroyed.

å°†å…¶è£…ç®±å¹¶å°†å…¶ç¼“å­˜åœ¨è¢«è°ƒç”¨æ–¹ä¸­ã€‚ä¸æ˜¯å°†æ•´ä¸ªæœªæ¥å†…è”åˆ°`AsyncIterator`ç±»å‹ä¸­ï¼Œè€Œæ˜¯åªå†…è”ä¸€ä¸ªæŒ‡é’ˆå­—æ§½ï¼Œè¿™æ ·å°±å¯ä»¥ç¼“å­˜å’Œé‡ç”¨`next`è¿”å›çš„`Box`ã€‚æ­¤ç­–ç•¥çš„ä¼˜ç‚¹æ˜¯ç¼“å­˜çš„æ¡†éšè¿­ä»£å™¨ç§»åŠ¨ï¼Œå¹¶ä¸”æœ‰å¯èƒ½åœ¨è°ƒç”¨æ–¹ä¹‹é—´é‡å¤ä½¿ç”¨ã€‚ç¼ºç‚¹æ˜¯ï¼Œä¸€æ—¦è°ƒç”¨æ–¹å®Œæˆè°ƒç”¨ï¼Œç¼“å­˜çš„æ¡†å°±ä¼šä¸€ç›´å­˜åœ¨ï¼Œç›´åˆ°å¯¹è±¡æœ¬èº«è¢«é”€æ¯ã€‚

**Have caller allocate maximal space.** Another strategy is to have the caller allocate a big chunk of space on the stack, one that should be big enough for every callee. If you know the callees your code will have to handle, and the futures for those callees are close enough in size, this strategy works well. Eric Holk recently released the \[stackfuture crate\] that can help automate it. **One problem with this strategy is that the caller has to know the size of all its callees.**

è®©è°ƒç”¨æ–¹åˆ†é…æœ€å¤§ç©ºé—´ã€‚å¦ä¸€ç§ç­–ç•¥æ˜¯è®©è°ƒç”¨è€…åœ¨å †æ ˆä¸Šåˆ†é…ä¸€å¤§å—ç©ºé—´ï¼Œè¯¥ç©ºé—´åº”è¯¥è¶³å¤Ÿå¤§ï¼Œä¾›æ¯ä¸ªè¢«è°ƒç”¨è€…ä½¿ç”¨ã€‚å¦‚æœæ‚¨çŸ¥é“æ‚¨çš„ä»£ç å°†å¿…é¡»å¤„ç†çš„è¢«è°ƒç”¨æ–¹ï¼Œå¹¶ä¸”è¿™äº›è¢«è°ƒç”¨æ–¹çš„æœªæ¥åœ¨å¤§å°ä¸Šè¶³å¤Ÿæ¥è¿‘ï¼Œåˆ™æ­¤ç­–ç•¥æ•ˆæœå¾ˆå¥½ã€‚åŸƒé‡Œå…‹Â·éœå…‹æœ€è¿‘å‘å¸ƒäº†[StackFutureæ¿æ¡ç®±]ï¼Œå®ƒå¯ä»¥å¸®åŠ©å®ç°è‡ªåŠ¨åŒ–ã€‚è¿™ç§ç­–ç•¥çš„ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œè°ƒç”¨æ–¹å¿…é¡»çŸ¥é“å…¶æ‰€æœ‰è¢«è°ƒç”¨æ–¹çš„å¤§å°ã€‚

**Have caller allocate some space, and fall back to boxing for large callees.** If you donâ€™t know the sizes of all your callees, or those sizes have a wide distribution, another strategy might be to have the caller allocate some amount of stack space (say, 128 bytes) and then have the callee invoke `Box` if that space is not enough.

è®©è°ƒç”¨è€…åˆ†é…ä¸€äº›ç©ºé—´ï¼Œå¹¶ä¸ºè¾ƒå¤§çš„è¢«è°ƒç”¨è€…å›é€€åˆ°æ‹³å‡»ã€‚å¦‚æœæ‚¨ä¸çŸ¥é“æ‰€æœ‰è¢«è°ƒç”¨è€…çš„å¤§å°ï¼Œæˆ–è€…è¿™äº›å¤§å°åˆ†å¸ƒå¾ˆå¹¿ï¼Œå¦ä¸€ç§ç­–ç•¥å¯èƒ½æ˜¯è®©è°ƒç”¨è€…åˆ†é…ä¸€å®šæ•°é‡çš„å †æ ˆç©ºé—´(ä¾‹å¦‚ï¼Œ128å­—èŠ‚)ï¼Œç„¶ååœ¨ç©ºé—´ä¸è¶³çš„æƒ…å†µä¸‹è®©è¢«è°ƒç”¨è€…è°ƒç”¨`Box`ã€‚

**Alloca on the caller side.** You might think you can store the size of the future to be returned in the vtable and then have the caller â€œallocaâ€ that space â€” i.e., bump the stack pointer by some dynamic amount. Interestingly, this doesnâ€™t work with Rustâ€™s async model. Async tasks require that the size of the stack frame is known up front. 

å‘¼å«æ–¹çš„Allocaã€‚æ‚¨å¯èƒ½è®¤ä¸ºæ‚¨å¯ä»¥åœ¨vtableä¸­å­˜å‚¨è¦è¿”å›çš„æœªæ¥çš„å¤§å°ï¼Œç„¶åè®©è°ƒç”¨è€…â€œallocaâ€è·å¾—è¯¥ç©ºé—´-å³ï¼Œå°†å †æ ˆæŒ‡é’ˆå¢åŠ ä¸€äº›åŠ¨æ€é‡ã€‚æœ‰è¶£çš„æ˜¯ï¼Œè¿™ä¸é€‚ç”¨äºRustçš„å¼‚æ­¥æ¨¡å‹ã€‚å¼‚æ­¥ä»»åŠ¡è¦æ±‚é¢„å…ˆçŸ¥é“å †æ ˆå¸§çš„å¤§å°ã€‚

**Side stack.** Similar to the previous suggestion, you could imagine having the async runtimes provide some kind of â€œdynamic side stackâ€ for each task.[^ada] We could then allocate the right amount of space on this stack. This is probably the most efficient option, but it assumes that the runtime is able to provide a dynamic stack. Runtimes like [embassy](https://github.com/embassy-rs/embassy) wouldnâ€™t be able to do this. Moreover, we donâ€™t have any sort of protocol for this sort of thing right now. Introducing a side-stack also starts to â€œeat awayâ€ at some of the appeal of Rustâ€™s async model, which is [designed to allocate the â€œperfect size stackâ€ up front](https://without.boats/blog/futures-and-segmented-stacks/) and avoid the need to allocate a â€œbig stack per taskâ€.[^heap]

ä¾§é¢å †å ã€‚ä¸å‰é¢çš„å»ºè®®ç±»ä¼¼ï¼Œæ‚¨å¯ä»¥æƒ³è±¡è®©å¼‚æ­¥è¿è¡Œæ—¶ä¸ºæ¯ä¸ªä»»åŠ¡æä¾›æŸç§â€œåŠ¨æ€ä¾§å †æ ˆâ€ã€‚ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥åœ¨æ­¤å †æ ˆä¸Šåˆ†é…é€‚å½“æ•°é‡çš„ç©ºé—´ã€‚è¿™å¯èƒ½æ˜¯æœ€æœ‰æ•ˆçš„é€‰æ‹©ï¼Œä½†å®ƒå‡å®šè¿è¡Œåº“èƒ½å¤Ÿæä¾›åŠ¨æ€å †æ ˆã€‚åƒEMBASSYè¿™æ ·çš„è¿è¡Œæ—¶æ— æ³•åšåˆ°è¿™ä¸€ç‚¹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ç›®å‰è¿˜æ²¡æœ‰é’ˆå¯¹è¿™ç±»äº‹æƒ…çš„ä»»ä½•ç±»å‹çš„åè®®ã€‚å¼•å…¥ä¾§å †æ ˆä¹Ÿå¼€å§‹â€œèš•é£Ÿâ€Rustçš„å¼‚æ­¥æ¨¡å‹çš„ä¸€äº›å¸å¼•åŠ›ï¼Œè¯¥æ¨¡å‹æ—¨åœ¨é¢„å…ˆåˆ†é…â€œå®Œç¾å¤§å°çš„å †æ ˆâ€ï¼Œå¹¶é¿å…â€œæ¯ä¸ªä»»åŠ¡åˆ†é…ä¸€ä¸ªå¤§å †æ ˆâ€çš„éœ€è¦ã€‚

[^heap]: Of course, without a side stack, we are left using mechanisms like `Box::new` to cover cases like dynamic dispatch or recursive functions. This becomes a kind of pessimistically sized segmented stack, where we allocate for each little piece of extra state that we need. A side stack might be an appealing middle ground, but because of cases like `embassy`, it canâ€™t be the only option.

å½“ç„¶ï¼Œå¦‚æœæ²¡æœ‰ä¾§å †æ ˆï¼Œæˆ‘ä»¬åªèƒ½ä½¿ç”¨`Boxï¼šï¼šnew`è¿™æ ·çš„æœºåˆ¶æ¥è¦†ç›–åŠ¨æ€è°ƒåº¦æˆ–é€’å½’å‡½æ•°ç­‰æƒ…å†µã€‚è¿™å˜æˆäº†ä¸€ç§æ‚²è§‚å¤§å°çš„åˆ†æ®µå †æ ˆï¼Œæˆ‘ä»¬ä¸ºæ‰€éœ€çš„æ¯ä¸€å°å—é¢å¤–çŠ¶æ€è¿›è¡Œåˆ†é…ã€‚ä¾§é¢å †æ ˆå¯èƒ½æ˜¯ä¸€ä¸ªå¾ˆå¸å¼•äººçš„ä¸­é—´ç«‹åœºï¼Œä½†ç”±äºåƒ`embassysâ€˜è¿™æ ·çš„æƒ…å†µï¼Œå®ƒä¸å¯èƒ½æ˜¯å”¯ä¸€çš„é€‰æ‹©ã€‚

[^ada]: I was intrigued to learn that this is what Ada does, and that Ada features like returning dynamically sized types are built on this model. Iâ€™m not sure how [SPARK](https://www.adacore.com/about-spark) and other Ada subsets that target embedded spaces manage that, Iâ€™d like to learn more about it.

æˆ‘å¾ˆæ„Ÿå…´è¶£åœ°äº†è§£åˆ°è¿™å°±æ˜¯Adaæ‰€åšçš„ï¼Œå¹¶ä¸”åƒè¿”å›åŠ¨æ€å¤§å°ç±»å‹è¿™æ ·çš„AdaåŠŸèƒ½éƒ½æ„å»ºåœ¨è¿™ä¸ªæ¨¡å‹ä¸Šã€‚æˆ‘ä¸ç¡®å®šSparkå’Œå…¶ä»–é’ˆå¯¹åµŒå…¥å¼ç©ºé—´çš„Adaå­é›†æ˜¯å¦‚ä½•åšåˆ°è¿™ä¸€ç‚¹çš„ï¼Œæˆ‘æƒ³äº†è§£æ›´å¤šã€‚

### Can async functions used with dyn be â€œnormalâ€?

### ä¸dynä¸€èµ·ä½¿ç”¨çš„å¼‚æ­¥åŠŸèƒ½å¯ä»¥æ˜¯â€œæ­£å¸¸çš„â€å—ï¼Ÿ

One of my initial goals for async functions in traits was that they should feel â€œas natural as possibleâ€. In particular, I wanted you to be able to use them with dynamic dispatch in just the same way as you would a synchronous function. In other words, I wanted this code to compile, and I would want it to work even if `use_dyn` were put into another crate (and therefore were compiled with no idea of who is calling it):

å¯¹äºç‰¹å¾ä¸­çš„å¼‚æ­¥åŠŸèƒ½ï¼Œæˆ‘æœ€åˆçš„ç›®æ ‡ä¹‹ä¸€æ˜¯è®©å®ƒä»¬æ„Ÿè§‰â€œå°½å¯èƒ½è‡ªç„¶â€ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘å¸Œæœ›æ‚¨èƒ½å¤Ÿåƒä½¿ç”¨åŒæ­¥å‡½æ•°ä¸€æ ·å°†å®ƒä»¬ä¸åŠ¨æ€åˆ†æ´¾ä¸€èµ·ä½¿ç”¨ã€‚æ¢å¥è¯è¯´ï¼Œæˆ‘å¸Œæœ›ç¼–è¯‘è¿™æ®µä»£ç ï¼Œå¹¶ä¸”å³ä½¿å°†`use_dyn`æ”¾å…¥å¦ä¸€ä¸ªç®±å­ä¸­(å› æ­¤ç¼–è¯‘æ—¶ä¸çŸ¥é“æ˜¯è°åœ¨è°ƒç”¨å®ƒ)ï¼Œæˆ‘ä¹Ÿå¸Œæœ›å®ƒèƒ½å¤Ÿå·¥ä½œï¼š

```rust
fn make_dyn<AI: AsyncIterator>(ai: AI) {
    use_dyn(&mut ai);
}

fn use_dyn(di: &mut dyn AsyncIterator) {
    di.next().await;
}
```

My hope was that we could make this code work *just as it is* by selecting some kind of default strategy that works most of the time, and then provide ways for you to pick other strategies for those code where the default strategy is not a good fit. The problem though is that there is no single default strategy that seems â€œobvious and right almost all of the timeâ€â€¦

æˆ‘çš„å¸Œæœ›æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡é€‰æ‹©æŸç§åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹éƒ½æœ‰æ•ˆçš„é»˜è®¤ç­–ç•¥æ¥ä½¿è¯¥ä»£ç æ­£å¸¸å·¥ä½œï¼Œç„¶åä¸ºé‚£äº›é»˜è®¤ç­–ç•¥ä¸å¤ªé€‚åˆçš„ä»£ç é€‰æ‹©å…¶ä»–ç­–ç•¥ã€‚ä½†é—®é¢˜æ˜¯ï¼Œæ²¡æœ‰å“ªä¸€ç§é»˜è®¤ç­–ç•¥ä¼¼ä¹åœ¨å‡ ä¹æ‰€æœ‰æ—¶é—´éƒ½æ˜¯â€œæ˜¾è€Œæ˜“è§å’Œæ­£ç¡®çš„â€â€¦

|Strategy	æˆ˜ç•¥|Downside	è´Ÿé¢å½±å“|
|--------|--------|
|Box it (with default allocator)	å°†å…¶è£…ç®±(ä½¿ç”¨é»˜è®¤åˆ†é…å™¨)|requires allocation, not especially efficient	éœ€è¦åˆ†é…ï¼Œä¸æ˜¯ç‰¹åˆ«é«˜æ•ˆ|
|Box it with cache on caller side	åœ¨å‘¼å«æ–¹ç«¯ä½¿ç”¨ç¼“å­˜å°†å…¶è£…ç®±|requires allocation	éœ€è¦åˆ†é…|
|Inline it into the iterator	å°†å…¶å†…è”åˆ°è¿­ä»£å™¨ä¸­|adds space to 	å¢åŠ ç©ºé—´åˆ°`AI`, doesnâ€™t work for 	\`Ai`ï¼Œä¸é€‚ç”¨äº`&self`	\`è‡ªæˆ‘`|
|Box it with cache on callee side	åœ¨è¢«å‘¼å«æ–¹ä¸€ä¾§ä½¿ç”¨ç¼“å­˜å°†å…¶è£…ç®±|requires allocation, adds space to 	éœ€è¦åˆ†é…ï¼Œæ·»åŠ ç©ºé—´åˆ°`AI`, doesnâ€™t work for 	\`Ai`ï¼Œä¸é€‚ç”¨äº`&self`	\`è‡ªæˆ‘`|
|Allocate maximal space	åˆ†é…æœ€å¤§ç©ºé—´|canâ€™t necessarily use that across crates, requires extensive interprocedural analysis	ä¸ä¸€å®šèƒ½è·¨æ¿æ¡ç®±ä½¿ç”¨ï¼Œéœ€è¦å¹¿æ³›çš„ç¨‹åºé—´åˆ†æ|
|Allocate some space, fallback	åˆ†é…ä¸€äº›ç©ºé—´ï¼Œåå¤‡|uses allocator, requires extensive interprocedural analysis or else random guesswork	ä½¿ç”¨åˆ†é…å™¨ï¼Œéœ€è¦å¹¿æ³›çš„è¿‡ç¨‹é—´åˆ†ææˆ–éšæœºçŒœæµ‹|
|Alloca on the caller side	å‘¼å«æ–¹çš„Alloca|incompatible with async Rust	ä¸å¼‚æ­¥é“é”ˆä¸å…¼å®¹|
|Side-stack	ä¾§å †å |requires cooperation from runtime and allocation	éœ€è¦æ¥è‡ªè¿è¡Œæ—¶å’Œåˆ†é…çš„åä½œ|

### The soul of Rust

### é“é”ˆä¹‹é­‚

This is where we get to the â€œsoul of Rustâ€. Looking at the above table, the strategy that seems the closest to â€œobviously correctâ€ is â€œbox itâ€. It works fine with separate compilation, fits great with Rustâ€™s async model, and it matches what people are doing today in practice. Iâ€™ve spoken with a fair number of people who use async Rust in production, and virtually all of them agreed that â€œbox by default, but let me control itâ€ would work great in practice.

è¿™å°±æ˜¯æˆ‘ä»¬åˆ°è¾¾â€œé“é”ˆä¹‹é­‚â€çš„åœ°æ–¹ã€‚çœ‹çœ‹ä¸Šé¢çš„è¡¨æ ¼ï¼Œçœ‹èµ·æ¥æœ€æ¥è¿‘â€œæ˜æ˜¾æ­£ç¡®â€çš„ç­–ç•¥æ˜¯â€œæŠŠå®ƒæ”¾åœ¨ç›’å­é‡Œâ€ã€‚å®ƒåœ¨å•ç‹¬ç¼–è¯‘çš„æƒ…å†µä¸‹å·¥ä½œå¾—å¾ˆå¥½ï¼Œéå¸¸é€‚åˆRustçš„å¼‚æ­¥æ¨¡å‹ï¼Œè€Œä¸”å®ƒç¬¦åˆä»Šå¤©äººä»¬åœ¨å®è·µä¸­æ‰€åšçš„äº‹æƒ…ã€‚æˆ‘ä¸ç›¸å½“å¤šåœ¨ç”Ÿäº§ä¸­ä½¿ç”¨Async Rustçš„äººäº¤è°ˆè¿‡ï¼Œå‡ ä¹æ‰€æœ‰äººéƒ½åŒæ„â€œé»˜è®¤æƒ…å†µä¸‹ï¼Œä½†è®©æˆ‘æ§åˆ¶å®ƒâ€åœ¨å®è·µä¸­ä¼šå¾ˆå¥½åœ°å·¥ä½œã€‚

And yet, when we floated the idea of using this as the default, Josh Triplett objected strenuously, and I think for good reason. Joshâ€™s core concern was that this would be crossing a line for Rust. Until now, there is no way to allocate heap memory without some kind of explicit operation (though that operation could be a function call). But if we wanted make â€œbox itâ€ the default strategy, then youâ€™d be able to write â€œinnocent lookingâ€ Rust code that nonetheless *is* invoking `Box::new`. In particular, it would be invoking `Box::new` each time that `next` is called, to box up the future. But that is very unclear from reading over `make_dyn` and `use_dyn`.

ç„¶è€Œï¼Œå½“æˆ‘ä»¬æå‡ºå°†æ­¤ä½œä¸ºé»˜è®¤è®¾ç½®çš„æƒ³æ³•æ—¶ï¼Œä¹”å¸ŒÂ·ç‰¹é‡Œæ™®è±ç‰¹å¼ºçƒˆåå¯¹ï¼Œæˆ‘è®¤ä¸ºè¿™æ˜¯æœ‰å……åˆ†ç†ç”±çš„ã€‚ä¹”å¸Œçš„æ ¸å¿ƒæ‹…å¿ƒæ˜¯ï¼Œè¿™å¯¹æ‹‰æ–¯ç‰¹æ¥è¯´æ˜¯è¶Šç•Œäº†ã€‚åˆ°ç›®å‰ä¸ºæ­¢ï¼Œå¦‚æœæ²¡æœ‰æŸç§æ˜¾å¼æ“ä½œ(å°½ç®¡è¯¥æ“ä½œå¯èƒ½æ˜¯å‡½æ•°è°ƒç”¨)ï¼Œå°±æ— æ³•åˆ†é…å †å†…å­˜ã€‚ä½†æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬å¸Œæœ›å°†â€œbox itâ€è®¾ç½®ä¸ºé»˜è®¤ç­–ç•¥ï¼Œé‚£ä¹ˆæ‚¨å¯ä»¥ç¼–å†™â€œçœ‹èµ·æ¥å¾ˆæ— è¾œâ€çš„Rustä»£ç ï¼Œä½†å®ƒä»ç„¶ä¼šè°ƒç”¨`Boxï¼šï¼šNew`ã€‚å…·ä½“åœ°è¯´ï¼Œå®ƒå°†åœ¨æ¯æ¬¡è°ƒç”¨`next`æ—¶è°ƒç”¨`Boxï¼šï¼šnew`ï¼Œä»¥è£…ç®±æœªæ¥ã€‚ä½†ä»é˜…è¯»`make_dyn`å’Œ`use_dyn`æ¥çœ‹ï¼Œè¿™ä¸€ç‚¹éå¸¸ä¸æ¸…æ¥šã€‚

As an example of where this might matter, it might be that you are writing some sensitive systems code where allocation is something you always do with great care. It doesnâ€™t mean the code is no-std, it may have access to an allocator, but you still would like to know exactly where you will be doing allocations. Today, you can audit the code by hand, scanning for â€œobviousâ€ allocation points like `Box::new` or `vec![]`. Under this proposal, while it would still be *possible*, the presence of an allocation in the code is much less obvious. The allocation is â€œinjectedâ€ as part of the vtable construction process. To figure out that this will happen, you have to know Rustâ€™s rules quite well, and you also have to know the signature of the callee (because in this case, the vtable is built as part of an implicit coercion). In short, scanning for allocation went from being relatively obvious to requiring a PhD in Rustology. Hmm.

ä¾‹å¦‚ï¼Œæ‚¨å¯èƒ½æ­£åœ¨ç¼–å†™ä¸€äº›æ•æ„Ÿçš„ç³»ç»Ÿä»£ç ï¼Œåœ¨è¿™äº›ä»£ç ä¸­ï¼Œåˆ†é…å§‹ç»ˆæ˜¯æ‚¨éå¸¸å°å¿ƒåœ°å¤„ç†çš„äº‹æƒ…ã€‚è¿™å¹¶ä¸æ„å‘³ç€ä»£ç æ˜¯éæ ‡å‡†çš„ï¼Œå®ƒå¯èƒ½å¯ä»¥è®¿é—®åˆ†é…å™¨ï¼Œä½†æ˜¯æ‚¨ä»ç„¶æƒ³çŸ¥é“æ‚¨å°†åœ¨å“ªé‡Œè¿›è¡Œåˆ†é…ã€‚å¦‚ä»Šï¼Œæ‚¨å¯ä»¥æ‰‹åŠ¨å®¡æ ¸ä»£ç ï¼Œæ‰«æ`Boxï¼šï¼šnew`æˆ–`vecï¼[]`ç­‰â€œæ˜æ˜¾â€çš„åˆ†é…ç‚¹ã€‚åœ¨è¿™ä¸€æè®®ä¸‹ï¼Œè™½ç„¶ä»æœ‰å¯èƒ½ï¼Œä½†ä»£ç ä¸­å­˜åœ¨åˆ†é…çš„æƒ…å†µå°±ä¸é‚£ä¹ˆæ˜æ˜¾äº†ã€‚ä½œä¸ºvtableæ„é€ è¿‡ç¨‹çš„ä¸€éƒ¨åˆ†ï¼Œè¯¥åˆ†é…è¢«â€œæ³¨å…¥â€ã€‚è¦ç¡®å®šè¿™æ˜¯å¦ä¼šå‘ç”Ÿï¼Œæ‚¨å¿…é¡»éå¸¸äº†è§£Rustçš„è§„åˆ™ï¼Œå¹¶ä¸”è¿˜å¿…é¡»çŸ¥é“è¢«è°ƒç”¨è€…çš„ç­¾å(å› ä¸ºåœ¨æœ¬ä¾‹ä¸­ï¼Œvtableæ˜¯ä½œä¸ºéšå¼å¼ºåˆ¶çš„ä¸€éƒ¨åˆ†æ„å»ºçš„)ã€‚ç®€è€Œè¨€ä¹‹ï¼Œæ‰«æåˆ†é…ä»ç›¸å¯¹æ˜æ˜¾åœ°å˜æˆäº†éœ€è¦Rustologyçš„åšå£«å­¦ä½ã€‚å—¯ã€‚

On the other hand, if scanning for allocations is what is important, we could address that in many ways. We could add an â€œallow by defaultâ€ lint to flag the points where the â€œdefault vtableâ€ is constructed, and you could enable it in your project. This way the compiler would warn you about the possible future allocation. In fact, even today, scanning for allocations is actually much harder than I made it ought to be: you can easily see if your function allocates, but you canâ€™t easily see what its callees do. You have to read deeply into all of your dependencies and, if there are function pointers or `dyn Trait` values, figure out what code is potentially being called. With compiler/language support, we could make that whole process much more first-class and better.

å¦ä¸€æ–¹é¢ï¼Œå¦‚æœæ‰«æåˆ†é…æ˜¯é‡è¦çš„ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡è®¸å¤šæ–¹å¼è§£å†³è¿™ä¸ªé—®é¢˜ã€‚æˆ‘ä»¬å¯ä»¥æ·»åŠ ä¸€ä¸ªâ€œé»˜è®¤å…è®¸â€çš„lintæ¥æ ‡è®°æ„é€ â€œé»˜è®¤vtableâ€çš„ç‚¹ï¼Œå¹¶ä¸”æ‚¨å¯ä»¥åœ¨é¡¹ç›®ä¸­å¯ç”¨å®ƒã€‚è¿™æ ·ï¼Œç¼–è¯‘å™¨å°±ä¼šè­¦å‘Šæ‚¨æœªæ¥å¯èƒ½çš„åˆ†é…ã€‚äº‹å®ä¸Šï¼Œå³ä½¿åœ¨ä»Šå¤©ï¼Œæ‰«æåˆ†é…å®é™…ä¸Šä¹Ÿæ¯”æˆ‘åº”è¯¥åšçš„è¦éš¾å¾—å¤šï¼šæ‚¨å¯ä»¥å¾ˆå®¹æ˜“åœ°çœ‹åˆ°æ‚¨çš„å‡½æ•°æ˜¯å¦è¿›è¡Œäº†åˆ†é…ï¼Œä½†æ‚¨ä¸èƒ½è½»æ¾åœ°çœ‹åˆ°å®ƒçš„è¢«è°ƒç”¨è€…åšäº†ä»€ä¹ˆã€‚æ‚¨å¿…é¡»æ·±å…¥é˜…è¯»æ‚¨çš„æ‰€æœ‰ä¾èµ–é¡¹ï¼Œå¦‚æœæœ‰å‡½æ•°æŒ‡é’ˆæˆ–`dyn Trait`å€¼ï¼Œåˆ™æ‰¾å‡ºå¯èƒ½è¢«è°ƒç”¨çš„ä»£ç ã€‚æœ‰äº†ç¼–è¯‘å™¨/è¯­è¨€æ”¯æŒï¼Œæˆ‘ä»¬å¯ä»¥ä½¿æ•´ä¸ªè¿‡ç¨‹å˜å¾—æ›´ä¸€æµå’Œæ›´å¥½ã€‚

In a way, though, the technical arguments are besides the point. â€œRust makes allocations explicitâ€ is widely seen as a key attribute of Rustâ€™s design. In making this change, we would be tweaking that rule to be something like â€Rust makes allocations explicit *most of the time*â€. This would be harder for users to understand, and it would introduce doubt as whether Rust *really* intends to be the kind of language that can replace C and C++[^coro].

ç„¶è€Œï¼Œåœ¨æŸç§ç¨‹åº¦ä¸Šï¼ŒæŠ€æœ¯ä¸Šçš„äº‰è®ºå¹¶ä¸æ˜¯é‡ç‚¹ã€‚â€œRustä½¿åˆ†é…æ˜¾å¼â€è¢«å¹¿æ³›è§†ä¸ºRustè®¾è®¡çš„ä¸€ä¸ªå…³é”®å±æ€§ã€‚åœ¨åšå‡ºè¿™ä¸€æ”¹å˜æ—¶ï¼Œæˆ‘ä»¬å°†æŠŠè¿™ä¸€è§„åˆ™è°ƒæ•´ä¸ºç±»ä¼¼äºâ€œé“é”ˆåœ¨å¤§éƒ¨åˆ†æ—¶é—´å†…æ˜ç¡®åˆ†é…â€çš„è§„åˆ™ã€‚è¿™ä¼šè®©ç”¨æˆ·æ›´éš¾ç†è§£ï¼Œä¹Ÿä¼šå¼•èµ·äººä»¬çš„æ€€ç–‘ï¼Œæ¯”å¦‚Rustæ˜¯å¦çœŸçš„æ‰“ç®—æˆä¸ºä¸€ç§å¯ä»¥å–ä»£Cå’ŒC++çš„è¯­è¨€ã€‚

[^coro]: Ironically, C++ itself inserts implicit heap allocations to help with coroutines!

å…·æœ‰è®½åˆºæ„å‘³çš„æ˜¯ï¼ŒC++æœ¬èº«æ’å…¥äº†éšå¼å †åˆ†é…æ¥å¸®åŠ©æ‰§è¡Œåç¨‹ï¼

### Looking to the Rustacean design principles for guidance

### ä»¥Rustaceançš„è®¾è®¡åŸåˆ™ä¸ºæŒ‡å¯¼

Some time back, Josh and I drew up a draft set of design principles for Rust. Itâ€™s interesting to look back on them and see what they have to say about this question:

ä¸ä¹…å‰ï¼Œä¹”å¸Œå’Œæˆ‘ä¸ºRustèµ·è‰äº†ä¸€å¥—è®¾è®¡åŸåˆ™è‰æ¡ˆã€‚å›é¡¾ä»–ä»¬ï¼Œçœ‹çœ‹ä»–ä»¬å¯¹è¿™ä¸ªé—®é¢˜æœ‰ä»€ä¹ˆçœ‹æ³•ï¼Œè¿™æ˜¯å¾ˆæœ‰è¶£çš„ï¼š

* âš™ï¸ Reliable: "if it compiles, it works"
* ğŸ Performant: "idiomatic code runs efficiently"
* ğŸ¥° Supportive: "the language, tools, and community are here to help"
* ğŸ§© Productive: "a little effort does a lot of work"
* ğŸ”§ Transparent: "you can predict and control low-level details"
* ğŸ¤¸ Versatile: "you can do anything with Rust"

Boxing by default, to my mind, scores as follows:

âš™ï¸Reliableï¼šâ€œå¦‚æœå®ƒç¼–è¯‘äº†ï¼Œå®ƒå°±èƒ½å·¥ä½œâ€ğŸPerformantï¼šâ€œæƒ¯ç”¨ä»£ç é«˜æ•ˆè¿è¡Œâ€ğŸ¥°Supportï¼šè¯­è¨€ã€å·¥å…·å’Œç¤¾åŒºåœ¨è¿™é‡Œå¸®åŠ©â€œğŸ§©Productiveï¼šâ€ä¸€ç‚¹åŠªåŠ›å°±èƒ½åšå¾ˆå¤šå·¥ä½œâ€œğŸ”§é€æ˜ï¼šâ€ä½ å¯ä»¥é¢„æµ‹å’Œæ§åˆ¶ä½çº§åˆ«çš„ç»†èŠ‚â€œğŸ¤¸å¤šåŠŸèƒ½ï¼šâ€ä½ å¯ä»¥ç”¨é“é”ˆåšä»»ä½•äº‹æƒ…â€œåœ¨æˆ‘çœ‹æ¥ï¼Œé»˜è®¤æƒ…å†µä¸‹ï¼Œå¾—åˆ†å¦‚ä¸‹ï¼š

* **ğŸ Performant: meh.** The real goal with performant is that the cleanest code also runs the *fastest*. Boxing on every dynamic call doesnâ€™t meet this goal, but something like â€œboxing with caller-side cachingâ€ or â€œhave caller allocate space and fall back to boxingâ€ very well might.
* **ğŸ§© Productive: yes!** Virtually every production user of async Rust that Iâ€™ve talked to has agreed that having code box by default would (but giving the option to do something else for tight loops) would be a great sweet spot for Rust.
* **ğŸ”§ Transparent: no.** As I wrote before, understanding when a call may box now requires a PhD in Rustology, so this definitely fails on transparency.

(The other principles are not affected in any notable way, I don't think.)

ğŸè¡¨æ¼”è€…ï¼šå—¯ã€‚Performantçš„çœŸæ­£ç›®æ ‡æ˜¯æœ€å¹²å‡€çš„ä»£ç ä¹Ÿè¿è¡Œå¾—æœ€å¿«ã€‚åœ¨æ¯ä¸ªåŠ¨æ€è°ƒç”¨ä¸Šè£…ç®±å¹¶ä¸èƒ½è¾¾åˆ°è¿™ä¸ªç›®æ ‡ï¼Œä½†æ˜¯åƒâ€œä½¿ç”¨è°ƒç”¨æ–¹ç¼“å­˜è¿›è¡Œè£…ç®±â€æˆ–â€œè®©è°ƒç”¨æ–¹åˆ†é…ç©ºé—´å¹¶å›é€€åˆ°è£…ç®±â€è¿™æ ·çš„äº‹æƒ…å¾ˆæœ‰å¯èƒ½è¾¾åˆ°è¿™ä¸ªç›®æ ‡ã€‚ğŸ§©Productiveï¼šæ˜¯çš„ï¼å®é™…ä¸Šï¼Œä¸æˆ‘äº¤è°ˆè¿‡çš„æ¯ä¸€ä½å¼‚æ­¥Rustçš„ç”Ÿäº§ç”¨æˆ·éƒ½åŒæ„ï¼Œé»˜è®¤è®¾ç½®ä»£ç æ¡†(ä½†å…è®¸é€‰æ‹©åšå…¶ä»–äº‹æƒ…æ¥å¤„ç†å¾ªç¯)å°†æ˜¯Rustçš„æœ€ä½³é€‰æ‹©ã€‚ğŸ”§é€æ˜ï¼šä¸ã€‚æ­£å¦‚æˆ‘ä¹‹å‰æ‰€å†™çš„é‚£æ ·ï¼Œç°åœ¨ç†è§£ä¸€æ¬¡é€šè¯å¯èƒ½éœ€è¦Rustologyçš„åšå£«å­¦ä½ï¼Œæ‰€ä»¥è¿™åœ¨é€æ˜åº¦æ–¹é¢è‚¯å®šæ˜¯å¤±è´¥çš„ã€‚(æˆ‘è®¤ä¸ºï¼Œå…¶ä»–åŸåˆ™æ²¡æœ‰å—åˆ°ä»»ä½•æ˜¾è‘—çš„å½±å“ã€‚)

### What the â€œuserâ€™s guide from the futureâ€ suggests

### ã€Šæœªæ¥ç”¨æˆ·æŒ‡å—ã€‹çš„å»ºè®®

These considerations led Tyler and I to a different design. In the [â€œUserâ€™s Guide From the Futureâ€](https://hackmd.io/@nikomatsakis/SJ2-az7sc) document from before, youâ€™ll see that it does not accept the running example just as is. Instead, if you were to compile the example code weâ€™ve been using thus far, youâ€™d get an error:

è¿™äº›è€ƒè™‘å¯¼è‡´æ³°å‹’å’Œæˆ‘è¿›è¡Œäº†ä¸åŒçš„è®¾è®¡ã€‚åœ¨å‰é¢çš„â€œUserâ€˜s Guide from the Futureâ€æ–‡æ¡£ä¸­ï¼Œæ‚¨å°†çœ‹åˆ°å®ƒå¹¶ä¸å®Œå…¨æ¥å—æ­£åœ¨è¿è¡Œçš„ç¤ºä¾‹ã€‚ç›¸åï¼Œå¦‚æœæ‚¨ç¼–è¯‘æˆ‘ä»¬åˆ°ç›®å‰ä¸ºæ­¢ä¸€ç›´åœ¨ä½¿ç”¨çš„ç¤ºä¾‹ä»£ç ï¼Œæ‚¨ä¼šå¾—åˆ°ä¸€ä¸ªé”™è¯¯ï¼š

```
error[E0277]: the type `AI` cannot be converted to a
              `dyn AsyncIterator` without an adapter
 --> src/lib.rs:3:23
  |
3 |     use_dyn(&mut ai);
  |                  ^^ adapter required to convert to `dyn AsyncIterator`
  |
  = help: consider introducing the `Boxing` adapter,
    which will box the futures returned by each async fn
3 |     use_dyn(&mut Boxing::new(ai));
                     ++++++++++++  +
```

As the error suggests, in order to get the boxing behavior, you have to opt-in via a type that we called `Boxing`[^bikeshed]:

å¦‚é”™è¯¯æ‰€ç¤ºï¼Œä¸ºäº†è·å¾—è£…ç®±è¡Œä¸ºï¼Œæ‚¨å¿…é¡»é€šè¿‡æˆ‘ä»¬ç§°ä¸º`Boxing`çš„ç±»å‹é€‰æ‹©åŠ å…¥ï¼š

[^bikeshed]: Suggestions for a better name very welcome.

å¯¹äºæ›´å¥½çš„åå­—çš„å»ºè®®éå¸¸å—æ¬¢è¿ã€‚

```rust
fn make_dyn<AI: AsyncIterator>(ai: AI) {
    use_dyn(&mut Boxing::new(ai));
    //          ^^^^^^^^^^^
}

fn use_dyn(di: &mut dyn AsyncIterator) {
    di.next().await;
}
```

Under this design, you can only create a `&mut dyn AsyncIterator` when the caller can verify that the `next` method returns a type from which a `dyn*` can be constructed. If thatâ€™s not the case, and itâ€™s usually not, you can use the `Boxing::new` adapter to create a `Boxing<AI>`. Via some kind of compiler magic that *ahem* we havenâ€™t fully worked out yet[^pay-no-attention], you could coerce a `Boxing<AI>` into a `dyn AsyncIterator`.

åœ¨è¿™ç§è®¾è®¡ä¸‹ï¼Œåªæœ‰å½“è°ƒç”¨æ–¹å¯ä»¥éªŒè¯`next`æ–¹æ³•è¿”å›ä¸€ä¸ªå¯ä»¥æ„é€ `dyn*`çš„ç±»å‹æ—¶ï¼Œæ‰èƒ½åˆ›å»º`&mut dyn AsyncIterator`ã€‚å¦‚æœä¸æ˜¯è¿™æ ·ï¼Œé€šå¸¸ä¹Ÿä¸æ˜¯è¿™æ ·ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨`Boxingï¼šï¼šnew`é€‚é…å™¨æ¥åˆ›å»º`Boxing<AI>`ã€‚é€šè¿‡æŸç§æˆ‘ä»¬è¿˜æ²¡æœ‰å®Œå…¨å¼„æ˜ç™½çš„ç¼–è¯‘å™¨é­”æœ¯ï¼Œä½ å¯ä»¥å¼ºè¿«ä¸€ä¸ª`Boxing<AI>`å˜æˆä¸€ä¸ª`dyn AsyncIteratorâ€˜ã€‚

[^pay-no-attention]: Pay no attention to the compiler author behind the curtain. ğŸª„ ğŸŒˆ Avert your eyes!

ä¸è¦ç†ä¼šå¹•åçš„ç¼–è¯‘å™¨ä½œè€…ã€‚ğŸª„ğŸŒˆæŠŠä½ çš„çœ¼ç›ç§»å¼€ï¼

**The details of the `Boxing` type need more work[^UMFchange], but the basic idea remains the same: require users to make *some* explicit opt-in to the default vtable strategy, which may indeed perform allocation.**

\`Boxing`ç±»å‹çš„ç»†èŠ‚éœ€è¦åšæ›´å¤šçš„å·¥ä½œï¼Œä½†åŸºæœ¬æ€æƒ³ä¿æŒä¸å˜ï¼šè¦æ±‚ç”¨æˆ·æ˜¾å¼åœ°é€‰æ‹©åŠ å…¥é»˜è®¤çš„vtableç­–ç•¥ï¼Œè¿™å¯èƒ½ç¡®å®ä¼šæ‰§è¡Œåˆ†é…ã€‚

[^UMFchange]: e.g., if you look closely at the [User's Guide from the Future](https://hackmd.io/@nikomatsakis/SJ2-az7sc), you'll see that it writes `Boxing::new(&mut ai)`, and not `&mut Boxing::new(ai)`. I go back and forth on this one.

ä¾‹å¦‚ï¼Œå¦‚æœä½ ä»”ç»†æŸ¥çœ‹æ¥è‡ªæœªæ¥çš„ç”¨æˆ·æŒ‡å—ï¼Œä½ ä¼šå‘ç°å®ƒå†™çš„æ˜¯`Boxingï¼šï¼šnew(&mut ai)`ï¼Œè€Œä¸æ˜¯`&mut Boxingï¼šï¼šnew(Ai)`ã€‚åœ¨è¿™ä¸ªé—®é¢˜ä¸Šï¼Œæˆ‘åå¤è€ƒè™‘ã€‚

### How does `Boxing` rank on the design principles?

### ã€Šæ‹³å‡»ã€‹åœ¨è®¾è®¡åŸåˆ™ä¸Šæ’åå¦‚ä½•ï¼Ÿ

To my mind, adding the `Boxing` adapter ranks as followsâ€¦

åœ¨æˆ‘çœ‹æ¥ï¼Œæ·»åŠ `Boxing`é€‚é…å™¨çš„æ’åå¦‚ä¸‹â€¦

* **ğŸ Performant: meh.** This is roughly the same as before. Weâ€™ll come back to this.
* **ğŸ¥° Supportive: yes!** The error message guides you to exactly what you need to do, and hopefully links to a well-written explanation that can help you learn about why this is required.
* **ğŸ§© Productive: meh.** Having to add `Boxing::new` call each time you create a `dyn AsyncIterator` is not great, but also on-par with other Rust papercuts.
* **ğŸ”§ Transparent: yes!** It is easy to see that boxing may occur in the future now.

This design is now transparent. Itâ€™s also less productive than before, but weâ€™ve tried to make up for it with supportiveness. â€œRust isnâ€™t always easy, but itâ€™s always helpful.â€

ğŸè¡¨æ¼”è€…ï¼šå—¯ã€‚è¿™ä¸ä¹‹å‰å¤§è‡´ç›¸åŒã€‚æˆ‘ä»¬ä¼šå›åˆ°è¿™ä¸ªè¯é¢˜çš„ã€‚ğŸ¥°Supportï¼šæ˜¯çš„ï¼è¯¥é”™è¯¯æ¶ˆæ¯å°†æŒ‡å¯¼æ‚¨å‡†ç¡®åœ°æ‰§è¡Œæ‰€éœ€æ“ä½œï¼Œå¹¶å¸Œæœ›é“¾æ¥åˆ°ä¸€ä¸ªå†™å¾—å¾ˆå¥½çš„è§£é‡Šï¼Œå¸®åŠ©æ‚¨äº†è§£ä¸ºä»€ä¹ˆéœ€è¦è¿™æ ·åšã€‚ğŸ§©Productiveï¼šMehã€‚æ¯æ¬¡åˆ›å»ºâ€˜dyn AsyncIteratorâ€™æ—¶éƒ½è¦æ·»åŠ `Boxingï¼šï¼šNew`è°ƒç”¨ï¼Œè¿™å¹¶ä¸æ˜¯å¾ˆå¥½ï¼Œä½†ä¹Ÿä¸å…¶ä»–é“é”ˆå‰ªçº¸ä¸ç›¸ä¸Šä¸‹ã€‚ğŸ”§é€æ˜ï¼šæ˜¯çš„ï¼ç°åœ¨å¾ˆå®¹æ˜“çœ‹å‡ºæ‹³å‡»å¯èƒ½ä¼šåœ¨æœªæ¥å‘ç”Ÿã€‚è¿™ç§è®¾è®¡ç°åœ¨æ˜¯é€æ˜çš„ã€‚å®ƒçš„ç”Ÿäº§åŠ›ä¹Ÿä½äºä»¥å‰ï¼Œä½†æˆ‘ä»¬è¯•å›¾ç”¨æ”¯æŒæ¥å¼¥è¡¥è¿™ä¸€ç‚¹ã€‚â€œç”Ÿé”ˆå¹¶ä¸æ€»æ˜¯é‚£ä¹ˆå®¹æ˜“ï¼Œä½†å®ƒæ€»æ˜¯æœ‰å¸®åŠ©çš„ã€‚â€

### Improving performance with a more complex ABI

### é€šè¿‡æ›´å¤æ‚çš„ABIæé«˜æ€§èƒ½

One thing that bugs me about the â€œbox by defaultâ€ strategy is that the performance is only â€œmehâ€. I like stories like `Iterator`, where you write nice code and you get tight loops. It bothers me that writing â€œniceâ€ async code yields a naive, middling efficiency story.

â€œé»˜è®¤è®¾ç½®æ¡†â€ç­–ç•¥è®©æˆ‘æ„Ÿåˆ°å›°æ‰°çš„ä¸€ä»¶äº‹æ˜¯ï¼Œå®ƒçš„æ€§èƒ½åªæœ‰â€œmehâ€ã€‚æˆ‘å–œæ¬¢ã€Šè¿­ä»£å™¨ã€‹è¿™æ ·çš„æ•…äº‹ï¼Œåœ¨è¿™ç§æ•…äº‹ä¸­ï¼Œä½ å†™å‡ºäº†å¾ˆå¥½çš„ä»£ç ï¼Œä½ å¾—åˆ°äº†ç´§å‡‘çš„å¾ªç¯ã€‚ç¼–å†™â€œå¥½çš„â€å¼‚æ­¥ä»£ç ä¼šäº§ç”Ÿä¸€ä¸ªå¤©çœŸçš„ã€ä¸­ç­‰æ•ˆç‡çš„æ•…äº‹ï¼Œè¿™è®©æˆ‘æ„Ÿåˆ°ä¸å®‰ã€‚

That said, I think this is something we could fix in the future, and I think we could fix it backwards compatibly. The idea would be to extend our ABI when doing virtual calls so that the caller has the *option* to provide some â€œscratch spaceâ€ for the callee. For example, we could then do things like analyze the binary to get a good guess as to how much stack space is needed (either by doing dataflow or just by looking at all implementations of `AsyncIterator`). We could then have the caller reserve stack space for the future and pass a pointer into the callee â€” the callee would still have the *option* of allocating, if for example, there wasnâ€™t enough stack space, but it could make use of the space in the common case.

ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘è®¤ä¸ºè¿™æ˜¯æˆ‘ä»¬æœªæ¥å¯ä»¥ä¿®å¤çš„ä¸œè¥¿ï¼Œæˆ‘è®¤ä¸ºæˆ‘ä»¬å¯ä»¥å‘åå…¼å®¹åœ°ä¿®å¤å®ƒã€‚æˆ‘ä»¬çš„æƒ³æ³•æ˜¯åœ¨è¿›è¡Œè™šæ‹Ÿè°ƒç”¨æ—¶æ‰©å±•æˆ‘ä»¬çš„ABIï¼Œä»¥ä¾¿è°ƒç”¨è€…å¯ä»¥é€‰æ‹©ä¸ºè¢«è°ƒç”¨è€…æä¾›ä¸€äº›â€œä¸´æ—¶ç©ºé—´â€ã€‚ä¾‹å¦‚ï¼Œç„¶åæˆ‘ä»¬å¯ä»¥åˆ†æäºŒè¿›åˆ¶æ–‡ä»¶ï¼Œä»¥å¾ˆå¥½åœ°çŒœæµ‹éœ€è¦å¤šå°‘å †æ ˆç©ºé—´(é€šè¿‡æ‰§è¡Œæ•°æ®æµæˆ–ä»…é€šè¿‡æŸ¥çœ‹`AsyncIteratorâ€˜çš„æ‰€æœ‰å®ç°)ã€‚ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥è®©è°ƒç”¨æ–¹ä¸ºå°†æ¥ä¿ç•™å †æ ˆç©ºé—´ï¼Œå¹¶å°†ä¸€ä¸ªæŒ‡é’ˆä¼ é€’ç»™è¢«è°ƒç”¨æ–¹-è¢«è°ƒç”¨æ–¹ä»æœ‰åˆ†é…çš„é€‰é¡¹ï¼Œä¾‹å¦‚ï¼Œå¦‚æœæ²¡æœ‰è¶³å¤Ÿçš„å †æ ˆç©ºé—´ï¼Œä½†åœ¨å¸¸è§æƒ…å†µä¸‹å®ƒå¯ä»¥åˆ©ç”¨è¿™äº›ç©ºé—´ã€‚

Interestingly, I think that if we did this, we would also be putting some pressure on Rustâ€™s â€œtransparencyâ€ story again. While Rustâ€™s leans heavily on optimizations to get performance, weâ€™ve generally restricted ourselves to simple, local ones like inlining; we donâ€™t require interprocedural dataflow in particular, although of course it helps (and LLVM does it). But getting a good estimate of how much stack space to reserve for potential calleees would violate that rule (weâ€™d also need some simple escape analysis, as I describe in [Appendix A](#Appendix-A-futures-that-escape-the-stack-frame)). All of this adds up to a bit of â€˜performance unpredictabilityâ€™. Still, I donâ€™t see this as a big problem, particularly since the fallback is just to use `Box::new`, and as weâ€™ve said, for most users that is perfectly adequate.

æœ‰è¶£çš„æ˜¯ï¼Œæˆ‘è®¤ä¸ºï¼Œå¦‚æœæˆ‘ä»¬è¿™æ ·åšï¼Œæˆ‘ä»¬ä¹Ÿä¼šå†æ¬¡å¯¹æ‹‰æ–¯ç‰¹çš„â€œé€æ˜åº¦â€æ•…äº‹æ–½åŠ ä¸€äº›å‹åŠ›ã€‚è™½ç„¶Ruståœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šä¾èµ–ä¼˜åŒ–æ¥è·å¾—æ€§èƒ½ï¼Œä½†æˆ‘ä»¬é€šå¸¸å°†è‡ªå·±é™åˆ¶åœ¨ç®€å•çš„æœ¬åœ°ä¼˜åŒ–ï¼Œå¦‚å†…è”ï¼›æˆ‘ä»¬ä¸éœ€è¦ç‰¹åˆ«çš„è¿‡ç¨‹é—´æ•°æ®æµï¼Œå°½ç®¡å®ƒå½“ç„¶æœ‰å¸®åŠ©(LLVMå°±æ˜¯è¿™æ ·åšçš„)ã€‚ä½†æ˜¯ï¼Œå¾ˆå¥½åœ°ä¼°è®¡ä¸ºæ½œåœ¨çš„è¢«è°ƒç”¨è€…ä¿ç•™å¤šå°‘å †æ ˆç©ºé—´å°†è¿åè¯¥è§„åˆ™(æˆ‘ä»¬è¿˜éœ€è¦ä¸€äº›ç®€å•çš„è½¬ä¹‰åˆ†æï¼Œå¦‚æˆ‘åœ¨é™„å½•Aä¸­æ‰€æè¿°çš„)ã€‚æ‰€æœ‰è¿™ä¸€åˆ‡åŠ åœ¨ä¸€èµ·ï¼Œå°±æ˜¯æœ‰ç‚¹â€œæ€§èƒ½çš„ä¸å¯é¢„æµ‹æ€§â€ã€‚å°½ç®¡å¦‚æ­¤ï¼Œæˆ‘ä¸è®¤ä¸ºè¿™æ˜¯ä¸€ä¸ªå¤§é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯å› ä¸ºåå¤‡åªæ˜¯ä½¿ç”¨`Boxï¼šï¼šnew`ï¼Œæ­£å¦‚æˆ‘ä»¬å·²ç»è¯´è¿‡çš„ï¼Œå¯¹äºå¤§å¤šæ•°ç”¨æˆ·æ¥è¯´ï¼Œè¿™æ˜¯å®Œå…¨è¶³å¤Ÿçš„ã€‚

### Picking another strategy, such as inlining

### é€‰æ‹©å¦ä¸€ç§ç­–ç•¥ï¼Œä¾‹å¦‚å†…è”

Of course, maybe you donâ€™t want to use `Boxing`. It would also be possible to construct other kinds of adapters, and they would work in a similar fashion. For example, an inlining adapter might look like:

å½“ç„¶ï¼Œä¹Ÿè®¸ä½ ä¸æƒ³ç”¨`æ‹³å‡»â€˜ã€‚è¿˜å¯ä»¥æ„å»ºå…¶ä»–ç±»å‹çš„é€‚é…å™¨ï¼Œå®ƒä»¬å°†ä»¥ç±»ä¼¼çš„æ–¹å¼å·¥ä½œã€‚ä¾‹å¦‚ï¼Œå†…è”é€‚é…å™¨å¯èƒ½å¦‚ä¸‹æ‰€ç¤ºï¼š

```rust
fn make_dyn<AI: AsyncIterator>(ai: AI) {
    use_dyn(&mut InlineAsyncIterator::new(ai));
    //           ^^^^^^^^^^^^^^^^^^^^^^^^
}
```

The `InlineAsyncIterator<AI>` type would add the extra space to store the future, so that when the `next` method is called, it writes the future into its own fields and then returns it to the caller. Similarly, a cached box adapter might be `&mut CachedAsyncIterator::new(ai)`, only it would use a field to cache the resulting `Box`.

\`InlineAsyncIterator<AI>`ç±»å‹å°†æ·»åŠ é¢å¤–çš„ç©ºé—´æ¥å­˜å‚¨æœªæ¥ï¼Œå› æ­¤å½“è°ƒç”¨`next`æ–¹æ³•æ—¶ï¼Œå®ƒå°†æœªæ¥å†™å…¥è‡ªå·±çš„å­—æ®µä¸­ï¼Œç„¶åå°†å…¶è¿”å›ç»™è°ƒç”¨æ–¹ã€‚åŒæ ·ï¼Œç¼“å­˜çš„Boxé€‚é…å™¨å¯èƒ½æ˜¯`&mut CachedAsyncIteratorï¼šï¼šnew(Ai)`ï¼Œåªæ˜¯å®ƒä¼šä½¿ç”¨ä¸€ä¸ªå­—æ®µæ¥ç¼“å­˜ç»“æœ`Box`ã€‚

You may have noticed that the inline/cached adapters include the name of the trait. Thatâ€™s because they arenâ€™t relying on compiler magic like Boxing, but are instead intended to be authored by end-users, and we donâ€™t yet have a way to be generic over any trait definition. (The proposal as we wrote it uses macros to generate an adapter type for any trait you wish to adapt.) This is something Iâ€™d love to address in the future. [You can read more about how adapters work here.](https://rust-lang.github.io/async-fundamentals-initiative/explainer/inline_async_iter_adapter.html)

æ‚¨å¯èƒ½å·²ç»æ³¨æ„åˆ°ï¼Œå†…è”/ç¼“å­˜é€‚é…å™¨åŒ…æ‹¬ç‰¹å¾çš„åç§°ã€‚è¿™æ˜¯å› ä¸ºå®ƒä»¬ä¸ä¾èµ–äºåƒBoxingé‚£æ ·çš„ç¼–è¯‘å™¨é­”åŠ›ï¼Œè€Œæ˜¯æ‰“ç®—ç”±æœ€ç»ˆç”¨æˆ·åˆ›ä½œï¼Œè€Œæˆ‘ä»¬è¿˜æ²¡æœ‰åŠæ³•åœ¨ä»»ä½•ç‰¹å¾å®šä¹‰ä¸Šå®ç°æ³›å‹ã€‚(æˆ‘ä»¬ç¼–å†™çš„ææ¡ˆä½¿ç”¨å®ä¸ºæ‚¨å¸Œæœ›é€‚åº”çš„ä»»ä½•ç‰¹æ€§ç”Ÿæˆé€‚é…å™¨ç±»å‹ã€‚)è¿™æ˜¯æˆ‘æœªæ¥å¾ˆä¹æ„è§£å†³çš„é—®é¢˜ã€‚æ‚¨å¯ä»¥åœ¨æ­¤å¤„é˜…è¯»æœ‰å…³é€‚é…å™¨å¦‚ä½•å·¥ä½œçš„æ›´å¤šä¿¡æ¯ã€‚

### Conclusion

### ç»“è®º

OK, so letâ€™s put it all together into a coherent design proposal:

å¥½çš„ï¼Œè®©æˆ‘ä»¬æŠŠæ‰€æœ‰è¿™äº›æ”¾åˆ°ä¸€ä¸ªè¿è´¯çš„è®¾è®¡æ–¹æ¡ˆä¸­ï¼š

* You cannot coerce from an arbitrary type `AI` into a `dyn AsyncIterator`. Instead, you must select an adaptor:
  * Typically you want `Boxing`, which has a decent performance profile and â€œjust worksâ€.
  * But users can write their own adapters to implement other strategies, such as `InlineAsyncIterator` or `CachingAsyncIterator`.
* From an implementation perspective:
  * When invoked via dynamic dispatch, async functions return a `dyn* Future`. The caller can invoke `poll` via virtual dispatch and invoke the (virtual) drop function when itâ€™s ready to dispose of the future.
  * The vtable created for `Boxing<AI>` will allocate a box to store the future `AI::next()` and use that to create the `dyn* Future`.
  * The vtable for other adapters can use whatever strategy they want. `InlineAsyncIterator<AI>`, for example, stores the `AI::next()` future into a field in the wrapper, takes a raw pointer to that field, and creates a `dyn* Future` from this raw pointer.
* Possible future extension for better performance:[^tmandry]
  * We modify the ABI for async trait functions (or any trait function using return-position impl trait) to allow the caller to optionally provide stack space. The `Boxing` adapter, if such stack space is available, will use it to avoid boxing when it can. This would have to be coupled with some compiler analysis to figure out how much to stack space to pre-allocate.

[^tmandry]: I should clarify that, while Tyler and I have discussed this, I don't know how he feels about it. I wouldn't call it 'part of the proposal' exactly, more like an extension I am interested in.

ä¸èƒ½å°†ä»»æ„ç±»å‹çš„`AI`å¼ºåˆ¶ä¸º`dyn AsyncIterator`ã€‚ç›¸åï¼Œä½ å¿…é¡»é€‰æ‹©ä¸€ä¸ªé€‚é…å™¨ï¼šé€šå¸¸ä½ æƒ³è¦`Boxing`ï¼Œå®ƒæœ‰ä¸é”™çš„æ€§èƒ½é…ç½®æ–‡ä»¶ï¼Œå¹¶ä¸”â€œåˆšåˆšå¥½â€ã€‚ä½†ç”¨æˆ·ä¹Ÿå¯ä»¥ç¼–å†™è‡ªå·±çš„é€‚é…å™¨æ¥å®ç°å…¶ä»–ç­–ç•¥ï¼Œå¦‚`InlineAsyncIterator`æˆ–`CachingAsyncIterator`ã€‚ä»å®ç°çš„è§’åº¦æ¥çœ‹ï¼šå½“é€šè¿‡åŠ¨æ€è°ƒåº¦è°ƒç”¨æ—¶ï¼Œå¼‚æ­¥å‡½æ•°è¿”å›`dyn*Future`ã€‚è°ƒç”¨è€…å¯ä»¥é€šè¿‡è™šæ‹Ÿåˆ†æ´¾è°ƒç”¨`poll`ï¼Œå¹¶åœ¨å‡†å¤‡å¥½å¤„ç½®æœªæ¥æ—¶è°ƒç”¨(è™šæ‹Ÿ)Dropå‡½æ•°ã€‚ä¸º`Boxing<AI>`åˆ›å»ºçš„vtableå°†åˆ†é…ä¸€ä¸ªæ¡†æ¥å­˜å‚¨æœªæ¥çš„`aiï¼šï¼šNext()`ï¼Œå¹¶ç”¨å®ƒæ¥åˆ›å»º`dyn*Future`ã€‚å…¶ä»–é€‚é…å™¨çš„vtableå¯ä»¥ä½¿ç”¨ä»–ä»¬æƒ³è¦çš„ä»»ä½•ç­–ç•¥ã€‚ä¾‹å¦‚ï¼Œ`InlineAsyncIterator<AI>`å°†æœªæ¥çš„`AIï¼šï¼šNext()`å­˜å‚¨åˆ°åŒ…è£…å™¨çš„ä¸€ä¸ªå­—æ®µä¸­ï¼Œè·å–æŒ‡å‘è¯¥å­—æ®µçš„åŸå§‹æŒ‡é’ˆï¼Œå¹¶ä»è¯¥åŸå§‹æŒ‡é’ˆåˆ›å»ºä¸€ä¸ª`dyn*Future`ã€‚ä¸ºäº†æ›´å¥½çš„æ€§èƒ½ï¼Œå¯èƒ½çš„æœªæ¥æ‰©å±•ï¼šæˆ‘ä»¬ä¿®æ”¹äº†å¼‚æ­¥ç‰¹å¾å‡½æ•°(æˆ–ä½¿ç”¨è¿”å›ä½ç½®Imlç‰¹å¾çš„ä»»ä½•ç‰¹å¾å‡½æ•°)çš„ABIï¼Œä»¥å…è®¸è°ƒç”¨è€…æœ‰é€‰æ‹©åœ°æä¾›å †æ ˆç©ºé—´ã€‚å¦‚æœå †æ ˆç©ºé—´å¯ç”¨ï¼Œ`Boxing`é€‚é…å™¨å°†åœ¨å¯èƒ½çš„æƒ…å†µä¸‹ä½¿ç”¨å®ƒæ¥é¿å…è£…ç®±ã€‚è¿™å¿…é¡»ä¸ä¸€äº›ç¼–è¯‘å™¨åˆ†æç›¸ç»“åˆï¼Œä»¥ç¡®å®šè¦é¢„å…ˆåˆ†é…çš„å †æ ˆç©ºé—´æœ‰å¤šå°‘ã€‚æˆ‘åº”è¯¥æ¾„æ¸…ä¸€ç‚¹ï¼Œå°½ç®¡æ³°å‹’å’Œæˆ‘å·²ç»è®¨è®ºè¿‡è¿™ä¸€ç‚¹ï¼Œä½†æˆ‘ä¸çŸ¥é“ä»–å¯¹æ­¤æœ‰ä½•æ„Ÿæƒ³ã€‚ç¡®åˆ‡åœ°è¯´ï¼Œæˆ‘ä¸ä¼šå°†å…¶ç§°ä¸ºâ€œæè®®çš„ä¸€éƒ¨åˆ†â€ï¼Œè€Œæ›´åƒæ˜¯æˆ‘æ„Ÿå…´è¶£çš„å»¶æœŸã€‚

This lets us express virtually any pattern. Its even *possible* to express side-stacks, if the runtime provides a suitable adapter (e.g., `TokioSideStackAdapter::new(ai)`), though if side-stacks become popular I would rather consider a more standard means to expose them.

è¿™è®©æˆ‘ä»¬å‡ ä¹å¯ä»¥è¡¨è¾¾ä»»ä½•æ¨¡å¼ã€‚å¦‚æœè¿è¡Œæ—¶æä¾›åˆé€‚çš„é€‚é…å™¨(ä¾‹å¦‚ï¼Œ`TokioSideStackAdapterï¼šï¼šnew(Ai)`)ï¼Œç”šè‡³å¯ä»¥è¡¨ç¤ºä¾§å †æ ˆï¼Œå°½ç®¡å¦‚æœä¾§å †æ ˆå˜å¾—æµè¡Œï¼Œæˆ‘å®æ„¿è€ƒè™‘ä¸€ç§æ›´æ ‡å‡†çš„æ–¹æ³•æ¥å…¬å¼€å®ƒä»¬ã€‚

The main downsides to this proposal are:

è¿™é¡¹æè®®çš„ä¸»è¦ç¼ºç‚¹æ˜¯ï¼š

* Users have to write `Boxing::new`, which is a productivity and learnability hit, but it avoids a big hit to transparency. Is that the right call? Iâ€™m still not entirely sure, though my heart increasingly says yes. Itâ€™s also something we could revisit in the future (e.g., and add a default adapter).
* If we opt to modify the ABI, weâ€™re adding some complexity there, but in exchange for potentially quite a lot of performance. I would expect us not to do this initially, but to explore it as an extension in the future once we have more data about how important it is. 

There is one pattern that we canâ€™t express: â€œhave caller allocate maximal spaceâ€. This pattern *guarantees* that heap allocation is not needed; the best we can do is a heuristic that *tries* to avoid heap allocation, since we have to consider public functions on crate boundaries and the like. To offer a guarantee, the argument type needs to change from `&mut dyn AsyncIterator` (which accepts any async iterator) to something narrower. This would also support futures that escape the stack frame (see [Appendix A](#Appendix-A-futures-that-escape-the-stack-frame) below). It seems likely that these details donâ€™t matter, and that either inline futures or heuristics would suffice, but if not, a crate like [stackfuture](https://github.com/microsoft/stackfuture) remains an option.

ç”¨æˆ·å¿…é¡»å†™`Boxingï¼šï¼šnew`ï¼Œè¿™ä¼šå½±å“å·¥ä½œæ•ˆç‡å’Œæ˜“å­¦æ€§ï¼Œä½†å®ƒé¿å…äº†å¯¹é€æ˜åº¦çš„é‡å¤§å½±å“ã€‚è¿™æ˜¯æ­£ç¡®çš„å†³å®šå—ï¼Ÿæˆ‘ä»ç„¶ä¸å®Œå…¨ç¡®å®šï¼Œå°½ç®¡æˆ‘çš„å¿ƒè¶Šæ¥è¶Šå¤šåœ°åŒæ„äº†ã€‚è¿™ä¹Ÿæ˜¯æˆ‘ä»¬å°†æ¥å¯ä»¥é‡æ–°è€ƒè™‘çš„äº‹æƒ…(ä¾‹å¦‚ï¼Œæ·»åŠ é»˜è®¤é€‚é…å™¨)ã€‚å¦‚æœæˆ‘ä»¬é€‰æ‹©ä¿®æ”¹ABIï¼Œæˆ‘ä»¬ä¼šåœ¨é‚£é‡Œå¢åŠ ä¸€äº›å¤æ‚æ€§ï¼Œä½†ä»¥æ½œåœ¨çš„ç›¸å½“å¤§çš„æ€§èƒ½ä¸ºäº¤æ¢ã€‚æˆ‘å¸Œæœ›æˆ‘ä»¬ä¸€å¼€å§‹ä¸ä¼šè¿™æ ·åšï¼Œä½†ä¸€æ—¦æˆ‘ä»¬æœ‰äº†æ›´å¤šå…³äºå®ƒæœ‰å¤šé‡è¦çš„æ•°æ®ï¼Œå°±ä¼šå°†å…¶ä½œä¸ºæœªæ¥çš„æ‰©å±•è¿›è¡Œæ¢ç´¢ã€‚æœ‰ä¸€ç§æ¨¡å¼æˆ‘ä»¬æ— æ³•è¡¨è¾¾ï¼šâ€œè®©è°ƒç”¨è€…åˆ†é…æœ€å¤§çš„ç©ºé—´â€ã€‚è¯¥æ¨¡å¼ä¿è¯ä¸éœ€è¦å †åˆ†é…ï¼›æˆ‘ä»¬æ‰€èƒ½åšçš„æœ€å¤šæ˜¯å°è¯•é¿å…å †åˆ†é…çš„å¯å‘å¼æ–¹æ³•ï¼Œå› ä¸ºæˆ‘ä»¬å¿…é¡»è€ƒè™‘æœºç®±è¾¹ç•Œä¸Šçš„å…¬å…±å‡½æ•°ç­‰ç­‰ã€‚ä¸ºäº†æä¾›ä¿è¯ï¼Œå‚æ•°ç±»å‹éœ€è¦ä»`&mut dyn AsyncIterator`(å®ƒæ¥å—ä»»ä½•å¼‚æ­¥è¿­ä»£å™¨)æ›´æ”¹ä¸ºæ›´çª„çš„ç±»å‹ã€‚è¿™ä¹Ÿå°†æ”¯æŒå¯¹å †æ ˆå¸§è¿›è¡Œè½¬ä¹‰çš„æœŸè´§(å‚è§ä¸‹é¢çš„é™„å½•A)ã€‚è¿™äº›ç»†èŠ‚ä¼¼ä¹å¹¶ä¸é‡è¦ï¼Œå†…è”æœŸè´§æˆ–å¯å‘å¼æ–¹æ³•å°±è¶³å¤Ÿäº†ï¼Œä½†å¦‚æœä¸æ˜¯è¿™æ ·ï¼ŒåƒStackFutureè¿™æ ·çš„æ¿æ¡ç®±ä»ç„¶æ˜¯ä¸€ä¸ªé€‰æ‹©ã€‚

### Comments?

### æœ‰ä»€ä¹ˆè¯„è®ºå—ï¼Ÿ

Please leave comments in [this internals thread](https://internals.rust-lang.org/t/blog-series-dyn-async-in-traits-continues/17403). Thanks!

è¯·åœ¨æ­¤å†…éƒ¨å¸–å­ä¸­ç•™ä¸‹è¯„è®ºã€‚è°¢è°¢!

### Appendix A: futures that escape the stack frame

### é™„å½•Aï¼šè½¬ä¹‰å †æ ˆå¸§çš„æœŸè´§

In all of this discussion, Iâ€™ve been assuming that the async call was followed closely by an await. But what happens if the future is not awaited, but instead is moved into the heap or other locations?

åœ¨æ‰€æœ‰è¿™äº›è®¨è®ºä¸­ï¼Œæˆ‘ä¸€ç›´å‡è®¾å¼‚æ­¥è°ƒç”¨ä¹‹åç´§è·Ÿç€ç­‰å¾…ã€‚ä½†æ˜¯ï¼Œå¦‚æœæœªæ¥æ²¡æœ‰è¢«ç­‰å¾…ï¼Œè€Œæ˜¯è¢«ç§»åˆ°å †æˆ–å…¶ä»–ä½ç½®ï¼Œä¼šå‘ç”Ÿä»€ä¹ˆå‘¢ï¼Ÿ

```rust
fn foo(x: &mut dyn AsyncIterator<Item = u32>) -> impl Future<Output = Option<u32>> + â€˜_ {
    x.next()
}
```

For boxing, this kind of code doesnâ€™t pose any problem at all. But if we had allocated space on the stack to store the future, examples like this would be a problem. So long as the scratch space is optional, with a fallback to boxing, this is no problem. We can do an escape analysis and avoid the use of scratch space for examples like this.

å¯¹äºæ‹³å‡»ï¼Œè¿™ç§ä»£ç æ ¹æœ¬ä¸ä¼šå¸¦æ¥ä»»ä½•é—®é¢˜ã€‚ä½†å¦‚æœæˆ‘ä»¬åœ¨å †æ ˆä¸Šåˆ†é…ç©ºé—´æ¥å­˜å‚¨æœªæ¥ï¼Œè¿™æ ·çš„ç¤ºä¾‹å°†æ˜¯ä¸€ä¸ªé—®é¢˜ã€‚åªè¦æš‚å­˜ç©ºé—´æ˜¯å¯é€‰çš„ï¼Œå¹¶åå¤‡åˆ°è£…ç®±ï¼Œè¿™å°±ä¸æˆé—®é¢˜ã€‚å¯¹äºè¿™æ ·çš„ä¾‹å­ï¼Œæˆ‘ä»¬å¯ä»¥è¿›è¡Œè½¬ä¹‰åˆ†æï¼Œé¿å…ä½¿ç”¨æš‚å­˜ç©ºé—´ã€‚

### Footnotes

### è„šæ³¨